{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tts_models/multilingual/multi-dataset/xtts_v2\n",
      "tts_models/multilingual/multi-dataset/xtts_v1.1\n",
      "tts_models/multilingual/multi-dataset/your_tts\n",
      "tts_models/multilingual/multi-dataset/bark\n",
      "tts_models/bg/cv/vits\n",
      "tts_models/cs/cv/vits\n",
      "tts_models/da/cv/vits\n",
      "tts_models/et/cv/vits\n",
      "tts_models/ga/cv/vits\n",
      "tts_models/en/ek1/tacotron2\n",
      "tts_models/en/ljspeech/tacotron2-DDC\n",
      "tts_models/en/ljspeech/tacotron2-DDC_ph\n",
      "tts_models/en/ljspeech/glow-tts\n",
      "tts_models/en/ljspeech/speedy-speech\n",
      "tts_models/en/ljspeech/tacotron2-DCA\n",
      "tts_models/en/ljspeech/vits\n",
      "tts_models/en/ljspeech/vits--neon\n",
      "tts_models/en/ljspeech/fast_pitch\n",
      "tts_models/en/ljspeech/overflow\n",
      "tts_models/en/ljspeech/neural_hmm\n",
      "tts_models/en/vctk/vits\n",
      "tts_models/en/vctk/fast_pitch\n",
      "tts_models/en/sam/tacotron-DDC\n",
      "tts_models/en/blizzard2013/capacitron-t2-c50\n",
      "tts_models/en/blizzard2013/capacitron-t2-c150_v2\n",
      "tts_models/en/multi-dataset/tortoise-v2\n",
      "tts_models/en/jenny/jenny\n",
      "tts_models/es/mai/tacotron2-DDC\n",
      "tts_models/es/css10/vits\n",
      "tts_models/fr/mai/tacotron2-DDC\n",
      "tts_models/fr/css10/vits\n",
      "tts_models/uk/mai/glow-tts\n",
      "tts_models/uk/mai/vits\n",
      "tts_models/zh-CN/baker/tacotron2-DDC-GST\n",
      "tts_models/nl/mai/tacotron2-DDC\n",
      "tts_models/nl/css10/vits\n",
      "tts_models/de/thorsten/tacotron2-DCA\n",
      "tts_models/de/thorsten/vits\n",
      "tts_models/de/thorsten/tacotron2-DDC\n",
      "tts_models/de/css10/vits-neon\n",
      "tts_models/ja/kokoro/tacotron2-DDC\n",
      "tts_models/tr/common-voice/glow-tts\n",
      "tts_models/it/mai_female/glow-tts\n",
      "tts_models/it/mai_female/vits\n",
      "tts_models/it/mai_male/glow-tts\n",
      "tts_models/it/mai_male/vits\n",
      "tts_models/ewe/openbible/vits\n",
      "tts_models/hau/openbible/vits\n",
      "tts_models/lin/openbible/vits\n",
      "tts_models/tw_akuapem/openbible/vits\n",
      "tts_models/tw_asante/openbible/vits\n",
      "tts_models/yor/openbible/vits\n",
      "tts_models/hu/css10/vits\n",
      "tts_models/el/cv/vits\n",
      "tts_models/fi/css10/vits\n",
      "tts_models/hr/cv/vits\n",
      "tts_models/lt/cv/vits\n",
      "tts_models/lv/cv/vits\n",
      "tts_models/mt/cv/vits\n",
      "tts_models/pl/mai_female/vits\n",
      "tts_models/pt/cv/vits\n",
      "tts_models/ro/cv/vits\n",
      "tts_models/sk/cv/vits\n",
      "tts_models/sl/cv/vits\n",
      "tts_models/sv/cv/vits\n",
      "tts_models/ca/custom/vits\n",
      "tts_models/fa/custom/glow-tts\n",
      "tts_models/bn/custom/vits-male\n",
      "tts_models/bn/custom/vits-female\n",
      "tts_models/be/common-voice/glow-tts\n",
      "vocoder_models/universal/libri-tts/wavegrad\n",
      "vocoder_models/universal/libri-tts/fullband-melgan\n",
      "vocoder_models/en/ek1/wavegrad\n",
      "vocoder_models/en/ljspeech/multiband-melgan\n",
      "vocoder_models/en/ljspeech/hifigan_v2\n",
      "vocoder_models/en/ljspeech/univnet\n",
      "vocoder_models/en/blizzard2013/hifigan_v2\n",
      "vocoder_models/en/vctk/hifigan_v2\n",
      "vocoder_models/en/sam/hifigan_v2\n",
      "vocoder_models/nl/mai/parallel-wavegan\n",
      "vocoder_models/de/thorsten/wavegrad\n",
      "vocoder_models/de/thorsten/fullband-melgan\n",
      "vocoder_models/de/thorsten/hifigan_v1\n",
      "vocoder_models/ja/kokoro/hifigan_v1\n",
      "vocoder_models/uk/mai/multiband-melgan\n",
      "vocoder_models/tr/common-voice/hifigan\n",
      "vocoder_models/be/common-voice/hifigan\n",
      "voice_conversion_models/multilingual/vctk/freevc24\n"
     ]
    }
   ],
   "source": [
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available üê∏TTS models\n",
    "print(\"\\n\".join(TTS().list_models().list_models()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_name, text, speaker_path, save_csv=True, display=True):\n",
    "    start = time.time()\n",
    "    # Load model\n",
    "    tts = TTS(model_name).to(device)\n",
    "    time_init = time.time() - start\n",
    "\n",
    "    output_name = get_output_name(model_name, speaker_path)\n",
    "\n",
    "    # Synthesize\n",
    "    if \"multilingual\" in model_name:\n",
    "        try:\n",
    "            start = time.time()\n",
    "            tts.tts_to_file(text=text, speaker_wav=speaker_path, file_path=output_name + '.wav', language=\"fr-fr\")\n",
    "            time_infer = time.time() - start\n",
    "        except:\n",
    "            try:\n",
    "                start = time.time()\n",
    "                tts.tts_to_file(text=text, speaker_wav=speaker_path, file_path=output_name + '.wav', language=\"fr\")\n",
    "                time_infer = time.time() - start\n",
    "            except:\n",
    "                try:\n",
    "                    start = time.time()\n",
    "                    tts.tts_to_file(text=text, speaker_wav=speaker_path, file_path=output_name + '.wav', language=\"fra\")\n",
    "                    time_infer = time.time() - start\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "    else:\n",
    "        start = time.time()\n",
    "        tts.tts_to_file(text=text, speaker_wav=speaker_path, file_path=output_name + '.wav')\n",
    "        time_infer = time.time() - start\n",
    "    \n",
    "    if display:\n",
    "        print(f\"\\n==============================================\\nModel: {model_name}\")\n",
    "        print(f\"Time to initialize the model: {time_init:.2f} s\")\n",
    "        print(f\"Time to synthesize the text: {time_infer:.2f} s\")\n",
    "\n",
    "    if save_csv:\n",
    "        save_to_csv(output_name, time_init, time_infer)\n",
    "\n",
    "def get_output_name(model_name, speaker_path):\n",
    "    if len(model_name.split('/')) != 4:\n",
    "        raise ValueError('model_name must be in the form of \"tts_model/language/model_tag/model_name\"')\n",
    "    _, language, model_tag, model_main = model_name.split('/')\n",
    "    return model_main + '-' + model_tag + '-' + language + '-' + speaker_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "def save_to_csv(output_name, time_init, time_infer):\n",
    "    df = pd.read_csv('time_analysis.csv', header=0)\n",
    "    if output_name in df['model'].values:\n",
    "        df = df[df['model'] != output_name]\n",
    "    df = df.append({'model': output_name, 'time_init': time_init, 'time_infer': time_infer}, ignore_index=True)\n",
    "    df.to_csv('time_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../../data/stored/assistant/voices/eliot_christon.mp3', '../../../data/stored/assistant/voices/eugenie_declaron.mp3', '../../../data/stored/assistant/voices/example_reference.mp3', '../../../data/stored/assistant/voices/jean_pierre_pernaut.mp3', '../../../data/stored/assistant/voices/perrine_laffont.mp3', '../../../data/stored/assistant/voices/pierre_faury.mp3', '../../../data/stored/assistant/voices/ptisham.mp3', '../../../data/stored/assistant/voices/roberto_caurand.mp3', '../../../data/stored/assistant/voices/teddy_riner.mp3', '../../../data/stored/assistant/voices/thomas_oxisoglou.mp3']\n",
      "Testing tts_models/fr/mai/tacotron2-DDC with speaker ../../../data/stored/assistant/voices/eliot_christon.mp3\n",
      " > tts_models/fr/mai/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/universal/libri-tts/fullband-melgan is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:C:\\Users\\echriston\\AppData\\Local\\tts\\tts_models--fr--mai--tacotron2-DDC\\scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: fullband_melgan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:24000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:C:\\Users\\echriston\\AppData\\Local\\tts\\vocoder_models--universal--libri-tts--fullband-melgan\\scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: fullband_melgan_generator\n",
      " > Discriminator Model: melgan_multiscale_discriminator\n",
      " > Text splitted to sentences.\n",
      "['Connaissez-vous Wemby?', 'Face aux New-Yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de San Antonio cent-trente √† cent-vingt-six.', 'A la fin du match, le Fran√ßais a envoy√© le ballon dans les tribunes!', 'R√©sultat, une amende de vingt-cinq-mille dollars.']\n",
      "k…în…õse vu w…õÃÉbi?\n",
      " [!] Character 'ÃÉ' not found in the vocabulary. Discarding it.\n",
      " > interpolating tts model output.\n",
      " > before interpolation : (80, 52)\n",
      " > after interpolation : torch.Size([1, 80, 78])\n",
      "   > Decoder stopped with `max_decoder_steps` 500\n",
      " > interpolating tts model output.\n",
      " > before interpolation : (80, 500)\n",
      " > after interpolation : torch.Size([1, 80, 750])\n",
      " > interpolating tts model output.\n",
      " > before interpolation : (80, 198)\n",
      " > after interpolation : torch.Size([1, 80, 297])\n",
      " > interpolating tts model output.\n",
      " > before interpolation : (80, 278)\n",
      " > after interpolation : torch.Size([1, 80, 417])\n",
      " > Processing time: 7.073880672454834\n",
      " > Real-time factor: 0.39821440398867564\n",
      "\n",
      "==============================================\n",
      "Model: tts_models/fr/mai/tacotron2-DDC\n",
      "Time to initialize the model: 0.61 s\n",
      "Time to synthesize the text: 7.12 s\n",
      "==============================================\n",
      "Testing tts_models/fr/css10/vits with speaker ../../../data/stored/assistant/voices/eliot_christon.mp3\n",
      " > tts_models/fr/css10/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echriston\\AppData\\Local\\Temp\\ipykernel_17360\\982808359.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': output_name, 'time_init': time_init, 'time_infer': time_infer}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Connaissez-vous Wemby?', 'Face aux New-Yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de San Antonio cent-trente √† cent-vingt-six.', 'A la fin du match, le Fran√ßais a envoy√© le ballon dans les tribunes!', 'R√©sultat, une amende de vingt-cinq-mille dollars.']\n",
      " > Processing time: 1.478450059890747\n",
      " > Real-time factor: 0.08792892235400206\n",
      "\n",
      "==============================================\n",
      "Model: tts_models/fr/css10/vits\n",
      "Time to initialize the model: 0.59 s\n",
      "Time to synthesize the text: 1.54 s\n",
      "==============================================\n",
      "Testing tts_models/fra/fairseq/vits with speaker ../../../data/stored/assistant/voices/eliot_christon.mp3\n",
      " > tts_models/fra/fairseq/vits is already downloaded.\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echriston\\AppData\\Local\\Temp\\ipykernel_17360\\982808359.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': output_name, 'time_init': time_init, 'time_infer': time_infer}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Connaissez-vous Wemby?', 'Face aux New-Yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de San Antonio cent-trente √† cent-vingt-six.', 'A la fin du match, le Fran√ßais a envoy√© le ballon dans les tribunes!', 'R√©sultat, une amende de vingt-cinq-mille dollars.']\n",
      "connaissez-vous wemby?\n",
      " [!] Character 'w' not found in the vocabulary. Discarding it.\n",
      "connaissez-vous wemby?\n",
      " [!] Character '?' not found in the vocabulary. Discarding it.\n",
      "face aux new-yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de san antonio cent-trente √† cent-vingt-six.\n",
      " [!] Character ',' not found in the vocabulary. Discarding it.\n",
      "face aux new-yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de san antonio cent-trente √† cent-vingt-six.\n",
      " [!] Character '.' not found in the vocabulary. Discarding it.\n",
      "a la fin du match, le fran√ßais a envoy√© le ballon dans les tribunes!\n",
      " [!] Character '!' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 5.5651280879974365\n",
      " > Real-time factor: 0.24716326558880072\n",
      "\n",
      "==============================================\n",
      "Model: tts_models/fra/fairseq/vits\n",
      "Time to initialize the model: 1.31 s\n",
      "Time to synthesize the text: 5.62 s\n",
      "==============================================\n",
      "Testing tts_models/acf/fairseq/vits with speaker ../../../data/stored/assistant/voices/eliot_christon.mp3\n",
      " > tts_models/acf/fairseq/vits is already downloaded.\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echriston\\AppData\\Local\\Temp\\ipykernel_17360\\982808359.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': output_name, 'time_init': time_init, 'time_infer': time_infer}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Connaissez-vous Wemby?', 'Face aux New-Yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de San Antonio cent-trente √† cent-vingt-six.', 'A la fin du match, le Fran√ßais a envoy√© le ballon dans les tribunes!', 'R√©sultat, une amende de vingt-cinq-mille dollars.']\n",
      "connaissez-vous wemby?\n",
      " [!] Character '?' not found in the vocabulary. Discarding it.\n",
      "face aux new-yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de san antonio cent-trente √† cent-vingt-six.\n",
      " [!] Character 'x' not found in the vocabulary. Discarding it.\n",
      "face aux new-yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de san antonio cent-trente √† cent-vingt-six.\n",
      " [!] Character ',' not found in the vocabulary. Discarding it.\n",
      "face aux new-yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de san antonio cent-trente √† cent-vingt-six.\n",
      " [!] Character 'q' not found in the vocabulary. Discarding it.\n",
      "face aux new-yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de san antonio cent-trente √† cent-vingt-six.\n",
      " [!] Character '√†' not found in the vocabulary. Discarding it.\n",
      "face aux new-yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de san antonio cent-trente √† cent-vingt-six.\n",
      " [!] Character '.' not found in the vocabulary. Discarding it.\n",
      "a la fin du match, le fran√ßais a envoy√© le ballon dans les tribunes!\n",
      " [!] Character '√ß' not found in the vocabulary. Discarding it.\n",
      "a la fin du match, le fran√ßais a envoy√© le ballon dans les tribunes!\n",
      " [!] Character '!' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 7.250030279159546\n",
      " > Real-time factor: 0.24825470069714922\n",
      "\n",
      "==============================================\n",
      "Model: tts_models/acf/fairseq/vits\n",
      "Time to initialize the model: 1.10 s\n",
      "Time to synthesize the text: 7.32 s\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echriston\\AppData\\Local\\Temp\\ipykernel_17360\\982808359.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': output_name, 'time_init': time_init, 'time_infer': time_infer}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "tts_to_test = [\n",
    "    # \"tts_models/multilingual/multi-dataset/xtts_v2\",\n",
    "    # \"tts_models/multilingual/multi-dataset/your_tts\",\n",
    "    \"tts_models/fr/mai/tacotron2-DDC\",\n",
    "    \"tts_models/fr/css10/vits\",\n",
    "    \"tts_models/fra/fairseq/vits\",\n",
    "    \"tts_models/acf/fairseq/vits\",\n",
    "]\n",
    "\n",
    "voice_folder = \"../../../data/stored/assistant/voices/\"\n",
    "\n",
    "speakers_to_test = [voice_folder + speaker for speaker in os.listdir(voice_folder) if speaker.endswith('.wav') or speaker.endswith('.flac') or speaker.endswith('.mp3')]\n",
    "print(speakers_to_test)\n",
    "\n",
    "text = \"Connaissez-vous Wemby? Face aux New-Yorkais, il avait inscrit quarante points, pris vingt rebonds et d√©livr√© sept passes d√©cisives lors de la victoire de San Antonio cent-trente √† cent-vingt-six. A la fin du match, le Fran√ßais a envoy√© le ballon dans les tribunes! R√©sultat, une amende de vingt-cinq-mille dollars.\"\n",
    "\n",
    "\n",
    "for model in tts_to_test:\n",
    "    if \"multilingual\" in model:\n",
    "        speakers = speakers_to_test\n",
    "    else:\n",
    "        speakers = [speakers_to_test[0]]\n",
    "    for speaker in speakers:\n",
    "        print(f\"Testing {model} with speaker {speaker}\")\n",
    "        test_model(model, text, speaker, save_csv=True, display=True)\n",
    "        print(\"==============================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
