{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import ollama\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "FRENCH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_from_prompt(prompt):\n",
    "    messages = []\n",
    "    with open(f\"prompts/{prompt}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        role = line.split(\" \")[0]\n",
    "        content = line[len(role)+1:]\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:06<00:00,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:07<00:00,  4.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:14<00:00,  4.99s/it]\n",
      "100%|██████████| 63/63 [05:06<00:00,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:07<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [07:30<00:00,  7.15s/it]\n",
      "100%|██████████| 63/63 [05:32<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:33<00:00,  5.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:10<00:00,  4.93s/it]\n",
      "100%|██████████| 63/63 [05:14<00:00,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:15<00:00,  5.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [04:57<00:00,  4.72s/it]\n",
      "100%|██████████| 63/63 [04:58<00:00,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [04:59<00:00,  4.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [04:52<00:00,  4.64s/it]\n",
      "100%|██████████| 63/63 [05:11<00:00,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:12<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [04:59<00:00,  4.76s/it]\n",
      "100%|██████████| 63/63 [05:17<00:00,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:18<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [04:59<00:00,  4.76s/it]\n",
      "100%|██████████| 63/63 [04:46<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [04:47<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:00<00:00,  4.77s/it]\n",
      "100%|██████████| 63/63 [05:09<00:00,  4.53s/it]"
     ]
    }
   ],
   "source": [
    "# for all prompts evaluate the model\n",
    "\n",
    "# all the text files in the prompts directory\n",
    "prompts = [f for f in os.listdir(\"prompts\") if f.endswith(\".txt\")]\n",
    "models = [\"openchat\", \"mistral\", \"llama2\", \"gemma\", \"openhermes\", \"qwen:4b\", \"qwen:7b\"]\n",
    "\n",
    "display = False\n",
    "display_minimal = True\n",
    "\n",
    "for round_number in range(17):\n",
    "\n",
    "    if display or display_minimal:print(\"Starting round\", round_number)\n",
    "\n",
    "    time_str = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    time_df = pd.DataFrame(columns=[\"model\", \"prompt\", \"time_per_char\", \"time_init\", \"time_total\"])\n",
    "\n",
    "    # new tqdm progress bar\n",
    "    pbar = tqdm.tqdm(total=len(models) * len(prompts))\n",
    "\n",
    "    for model in models:\n",
    "        if display:print(f\"  Model: {model}\")\n",
    "        ollama.chat(\n",
    "            model=model,\n",
    "            messages=[],\n",
    "            stream=False\n",
    "        )\n",
    "        for prompt in prompts:\n",
    "            if display:print(f\"Prompt: {prompt}\")\n",
    "            messages = messages_from_prompt(prompt)\n",
    "\n",
    "            response = \"\"\n",
    "            first_chunk = True\n",
    "            start = time.time()\n",
    "            stream = ollama.chat(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                stream=True\n",
    "            )\n",
    "            for chunk in stream:\n",
    "                if first_chunk:\n",
    "                    before_stream = time.time()\n",
    "                    first_chunk = False\n",
    "                response += chunk['message']['content']\n",
    "                if display:print(response, end=\"\\r\")\n",
    "            end = time.time()\n",
    "\n",
    "            new_df = pd.DataFrame([{\n",
    "                \"model\": model,\n",
    "                \"prompt\": prompt,\n",
    "                \"time_per_char\": (end - before_stream) / len(response),\n",
    "                \"time_init\": before_stream - start,\n",
    "                \"time_total\": end - start\n",
    "            }])\n",
    "            if len(time_df) == 0:\n",
    "                time_df = new_df.copy()\n",
    "            else:\n",
    "                time_df = pd.concat([time_df, new_df])\n",
    "            if display:print(f\"Time: {end - start}\")\n",
    "            model_str = model.replace(\":\", \"\")\n",
    "            with open(f\"responses/{model_str}_chat_{time_str}_{prompt}\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(response)\n",
    "            \n",
    "            # update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "    # write the time df to a file\n",
    "    with open(f\"time_dfs/time_df_{time_str}.csv\", \"w\") as f:\n",
    "        time_df.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
