{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import ollama\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "FRENCH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_from_prompt(prompt):\n",
    "    messages = []\n",
    "    with open(f\"prompts/{prompt}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        role = line.split(\" \")[0]\n",
    "        content = line[len(role)+1:]\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all prompts evaluate the model\n",
    "\n",
    "# all the text files in the prompts directory\n",
    "prompts = [f for f in os.listdir(\"prompts\") if f.endswith(\".txt\")]\n",
    "# models = [\"gemma\", \"llama2\", \"mistral\", \"openbuddy-mistral\", \"openchat\", \"openhermes\", \"qwen:4b\", \"qwen:7b\", \"vigogne\", \"vigostral\"]\n",
    "models = [\"openbuddy-mistral\", \"vigogne\", \"vigostral\"]\n",
    "\n",
    "display = False\n",
    "display_minimal = True\n",
    "\n",
    "for round_number in range(500):\n",
    "\n",
    "    if display or display_minimal:print(\"Starting round\", round_number)\n",
    "\n",
    "    time_str = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    time_df = pd.DataFrame(columns=[\"model\", \"prompt\", \"time_per_char\", \"time_init\", \"time_total\"])\n",
    "\n",
    "    # new tqdm progress bar\n",
    "    pbar = tqdm.tqdm(total=len(models) * len(prompts))\n",
    "\n",
    "    for model in models:\n",
    "        if display:print(f\"  Model: {model}\")\n",
    "        ollama.chat(\n",
    "            model=model,\n",
    "            messages=[],\n",
    "            stream=False\n",
    "        )\n",
    "        for prompt in prompts:\n",
    "            if display:print(f\"Prompt: {prompt}\")\n",
    "            messages = messages_from_prompt(prompt)\n",
    "\n",
    "            response = \"\"\n",
    "            first_chunk = True\n",
    "            start = time.time()\n",
    "            stream = ollama.chat(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                stream=True\n",
    "            )\n",
    "            for chunk in stream:\n",
    "                if first_chunk:\n",
    "                    before_stream = time.time()\n",
    "                    first_chunk = False\n",
    "                response += chunk['message']['content']\n",
    "                if display:print(response, end=\"\\r\")\n",
    "            end = time.time()\n",
    "\n",
    "            new_df = pd.DataFrame([{\n",
    "                \"model\": model,\n",
    "                \"prompt\": prompt,\n",
    "                \"time_per_char\": (end - before_stream) / len(response) if len(response) > 0 else end - before_stream,\n",
    "                \"time_init\": before_stream - start,\n",
    "                \"time_total\": end - start\n",
    "            }])\n",
    "            if len(time_df) == 0:\n",
    "                time_df = new_df.copy()\n",
    "            else:\n",
    "                time_df = pd.concat([time_df, new_df])\n",
    "            if display:print(f\"Time: {end - start}\")\n",
    "            model_str = model.replace(\":\", \"\")\n",
    "            with open(f\"responses/{model_str}_chat_{time_str}_{prompt}\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(response)\n",
    "            \n",
    "            # update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "    # write the time df to a file\n",
    "    with open(f\"time_dfs/time_df_{time_str}.csv\", \"w\") as f:\n",
    "        time_df.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
